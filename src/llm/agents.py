import aiohttp
import asyncio
import logging

from bs4 import BeautifulSoup
from langgraph.graph import StateGraph, END, START
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
from langchain_core.output_parsers import JsonOutputParser
from langgraph.graph.state import CompiledStateGraph

from src.core.exceptions import (
    ExceptClientError,
    ExceptTimeoutError,
    ExceptClientResponseError,
)
from src.llm.llm_states import ParsingState, RecipesList
from src.core.config import setting
from src.core.config import configure_logging


configure_logging(logging.INFO)
logger = logging.getLogger(__name__)


class ParsingAgent:
    def __init__(self, model_name: str = "gpt-4o-mini", temperature: float = 0.1):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞"""
        self.llm = ChatOpenAI(
            model=model_name,
            api_key=setting.llm.openrouter_api_key.get_secret_value(),
            base_url="https://api.aitunnel.ru/v1/",
            temperature=temperature,
        )
        self.workflow = self._create_workflow()

    def _create_workflow(self) -> CompiledStateGraph:
        workflow = StateGraph(ParsingState)

        workflow.add_node("parsing_site", self._parsing_site_ai_node)

        workflow.add_edge(START, "parsing_site")
        workflow.add_edge("parsing_site", END)

        return workflow.compile()

    async def _fetch_webpage(self, state: ParsingState, timeout=30, retries=2) -> str:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü—ã"""

        url: str = state["url"]
        logger.info(f"Start fetch webpage {url}")
        default_headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }

        timeout_obj = aiohttp.ClientTimeout(total=timeout)
        for attempt in range(retries + 1):
            try:
                async with aiohttp.ClientSession(
                    timeout=timeout_obj, headers=default_headers
                ) as session:
                    async with session.get(url) as response:
                        response.raise_for_status()

                        return await response.text()

            except aiohttp.ClientResponseError as e:
                logger.warning(
                    f"–û—à–∏–±–∫–∞ ClientResponseError –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {url}"
                )
                print(f"–û—à–∏–±–∫–∞ ClientResponseError –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {url}")
                raise ExceptClientResponseError(e)

            except aiohttp.ClientError as e:
                logger.warning(f"–û—à–∏–±–∫–∞ ClientError –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {url}")
                print(f"–û—à–∏–±–∫–∞ ClientError –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {url}")
                raise ExceptClientError(e)

            except asyncio.TimeoutError:
                logger.warning(
                    f"–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {url}, –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{retries + 1}"
                )
                print(
                    f"–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {url}, –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{retries + 1}"
                )
                if attempt < retries:
                    await asyncio.sleep(2**attempt)
                else:
                    raise ExceptTimeoutError(f"–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {url}")

    async def _extract_text_content(self, html_content: str):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å–æ —Å–∫–∞—á–µ–Ω–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ò–Ω—Ç–µ—Ä–Ω–µ—Ç"""

        def sync_parse():
            soup = BeautifulSoup(html_content, "html.parser")
            for element in soup(["script", "style", "nav", "footer", "header"]):
                element.decompose()
            text = soup.get_text(separator="\n", strip=True)
            lines = [line.strip() for line in text.split("\n") if line.strip()]
            return "\n".join(lines[:2000])

        logger.info("Start extract text from content")
        return await asyncio.to_thread(sync_parse)

    async def _parsing_site_ai_node(self, state: ParsingState) -> dict[str, any]:
        try:
            html_content = await self._fetch_webpage(state=state)
        except ExceptClientResponseError as e:
            if e.status == 404:
                return {"status": "–°—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"}
            elif e.status in (401, 403):
                return {"status": "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø—Ä–∞–≤–æ –¥–æ—Å—Ç—É–ø–∞"}
            else:
                return {"status": f"–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞ —Å –∫–æ–¥–æ–º {e.status}"}
        except ExceptClientError:
            return {"status": "–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–∏—Å–∞"}
        except ExceptTimeoutError:
            return {"status": "–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"}

        content = await self._extract_text_content(html_content=html_content)

        # —Å–æ–∑–¥–∞—ë–º –ø–∞—Ä—Å–µ—Ä –¥–ª—è —Å–ø–∏—Å–∫–∞ —Ä–µ—Ü–µ–ø—Ç–æ–≤
        parser = JsonOutputParser(pydantic_object=RecipesList)

        prompt = PromptTemplate(
            input_variables=["content"],
            partial_variables={"format_instructions": parser.get_format_instructions()},
            template="""
                –¢—ã –∫—É–ª–∏–Ω–∞—Ä–Ω—ã–π –±–ª–æ–≥–µ—Ä, –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π —Ç–µ–∫—Å—Ç —Ä–µ—Ü–µ–ø—Ç–æ–≤.
                –ù–∞–π–¥–∏ –≤—Å–µ —Ä–µ—Ü–µ–ø—Ç—ã –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –∏ –≤–µ—Ä–Ω–∏ –∏—Ö –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ –∫–∞–∫ —Å–ø–∏—Å–æ–∫.
                –ö–∞–∂–¥—ã–π —Ä–µ—Ü–µ–ø—Ç –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –ø–æ–ª—è: title, ingredients, description, category.
            
                {content}
            
                {format_instructions}
            
                –¢–æ–ª—å–∫–æ JSON!
                """,
        )

        messages = [
            SystemMessage(content="–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∫—É–ª–∏–Ω–∞—Ä–∏–∏."),
            HumanMessage(content=prompt.format(content=content)),
        ]

        response = await self.llm.ainvoke(messages)

        try:
            # parser –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Å–ø–∏—Å–æ–∫ —Ä–µ—Ü–µ–ø—Ç–æ–≤
            res_json = parser.parse(response.content)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–∑–±–æ—Ä–µ JSON: {e}")
            return {"status": f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}"}

        return {"status": "Ok", "recipes": res_json["recipes"]}

    async def classify(self, url: str):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ä–µ—Ü–µ–ø—Ç–æ–≤ —Å –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        initial_state = {
            "url": url,
            "status": "Ok",
            "recipes": [],  # —Å–ø–∏—Å–æ–∫ —Ä–µ—Ü–µ–ø—Ç–æ–≤, –∑–∞–ø–æ–ª–Ω—è–µ—Ç—Å—è –≤ —Ö–æ–¥–µ —Ä–∞–±–æ—Ç—ã –ø–∞–π–ø–ª–∞–π–Ω–∞
        }

        result = await self.workflow.ainvoke(initial_state)

        state_result = {
            "status": result["status"],
            "url": url,
            "recipes": result.get("recipes", []),
        }

        return state_result


async def main():
    app = ParsingAgent()
    res = await app.classify(
        "https://share.google/mhpd7DAqaCSwPcnV8"
        # "https://www.kp.ru/family/eda/retsept-glintvejna"
        # "https://1000.menu/cooking/90658-pasta-orzo-s-gribami-i-slivkami"
        # "https://share.google/iPyxfhgn5gFRPTRNW"
    )

    if res["status"].lower() == "ok":
        print("\n===== –†–ï–ó–£–õ–¨–¢–ê–¢ =====\n")

        recipes = res.get("recipes", [])
        if len(recipes) > 1:
            print(f"–ù–∞–π–¥–µ–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–µ—Ü–µ–ø—Ç–æ–≤: {len(recipes)}\n")
            multiple = True
        else:
            multiple = False

        for index, recipe in enumerate(recipes, start=1):
            if multiple:
                print(f"–†–µ—Ü–µ–ø—Ç ‚Ññ{index}")
                print("‚Äï" * 40)

            print(f"üçΩ  –ù–∞–∑–≤–∞–Ω–∏–µ: {recipe.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}")
            print(f"üìÇ  –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {recipe.get('category', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}\n")

            print("üßÇ  –ò–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã:")
            ingredients = recipe.get("ingredients", {})
            if ingredients:
                for ingredient, amount in ingredients.items():
                    print(f"   ‚Ä¢ {ingredient}: {amount}")
            else:
                print("   (–∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã –Ω–µ —É–∫–∞–∑–∞–Ω—ã)")

            print("\nüë®‚Äçüç≥  –≠—Ç–∞–ø—ã –ø—Ä–∏–≥–æ—Ç–æ–≤–ª–µ–Ω–∏—è:")
            steps = recipe.get("description", [])
            if steps:
                for step_num, step in enumerate(steps, start=1):
                    print(f"   {step_num}. {step}")
            else:
                print("   (—à–∞–≥–∏ –Ω–µ —É–∫–∞–∑–∞–Ω—ã)")

            print("\n" + "=" * 50 + "\n")

    else:
        print(f"–û—à–∏–±–∫–∞: {res['status']}")


if __name__ == "__main__":

    asyncio.run(main())
